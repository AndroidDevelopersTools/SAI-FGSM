# SAI-FGSM

We have been studying methods of adversarial attacks for a long time, especially in FGSM. We have continuously optimized our methods and produced a series of executable scripts.

If you just want to reproduce my experiment, you can directly use the code with the v19 logo.

Recommended environment:
tensorflow 2.1
python 3.7
